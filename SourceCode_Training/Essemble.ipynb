{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6583,
     "status": "ok",
     "timestamp": 1763656551019,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "Xx6KE-U5G8aO",
    "outputId": "2c3ae927-5def-4350-8e99-bc77ce1f5f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikeras) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from scikeras) (1.6.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (3.15.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.5.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (25.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 45606,
     "status": "ok",
     "timestamp": 1763656596631,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "sczvBZnqcMpw"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os, re, sys, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Keras 3 (standalone) + TF backend\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, initializers\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Embedding, Conv1D, GlobalMaxPooling1D, Reshape, Dense, Dropout,\n",
    "    Flatten, MaxPooling1D, Input, Concatenate, LSTM, Bidirectional\n",
    ")\n",
    "\n",
    "from tensorflow.keras import backend as K, initializers, regularizers, constraints\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# NumPy linalg\n",
    "from numpy import array, argmax\n",
    "from numpy.linalg import eig, norm as LA_norm, linalg as la\n",
    "\n",
    "# scikit‑learn 1.5+\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# SciKeras (thay cho keras.wrappers.scikit_learn.KerasClassifier đã deprecated)\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# LightGBM (import mới)\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763656596636,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "8f_tG_8HcQcc"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "def parse_stream(f, comment=b'#'):\n",
    "    name = None\n",
    "    sequence = []\n",
    "    for line in f:\n",
    "        if line.startswith(comment):\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        if line.startswith(b'>'):\n",
    "            if name is not None:\n",
    "                yield name, b''.join(sequence)\n",
    "            name = line[1:]\n",
    "            sequence = []\n",
    "        else:\n",
    "            sequence.append(line.upper())\n",
    "    if name is not None:\n",
    "        yield name, b''.join(sequence)\n",
    "\n",
    "def fasta2csv(inFasta):\n",
    "    FastaRead=pd.read_csv(inFasta,header=None)\n",
    "    print(FastaRead.shape)\n",
    "    print(FastaRead.head())\n",
    "    seqNum=int(FastaRead.shape[0]/2)\n",
    "    csvFile=open(\"testFasta.csv\",\"w\")\n",
    "    csvFile.write(\"PID,Seq\\n\")\n",
    "\n",
    "    #print(\"Lines:\",FastaRead.shape)\n",
    "    #print(\"Seq Num:\",seqNum)\n",
    "    for i in range(seqNum):\n",
    "      csvFile.write(str(FastaRead.iloc[2*i,0])+\",\"+str(FastaRead.iloc[2*i+1,0])+\"\\n\")\n",
    "\n",
    "\n",
    "    csvFile.close()\n",
    "    TrainSeqLabel=pd.read_csv(\"testFasta.csv\",header=0)\n",
    "    path=\"testFasta.csv\"\n",
    "    if os.path.exists(path):\n",
    "\n",
    "        os.remove(path)\n",
    "\n",
    "    return TrainSeqLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1763656596641,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "IHUkokdocWyV"
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        # W_regularizer:\n",
    "        # b_regularizer:\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        # W_constraint:\n",
    "        # b_constraint:\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        '''\n",
    "        keras.backend.cast(x, dtype):\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        '''\n",
    "        keras.backend.epsilon():\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"step_dim\": self.step_dim,\n",
    "            \"bias\": self.bias,\n",
    "            \"W_regularizer\": None,\n",
    "            \"b_regularizer\": None,\n",
    "            \"W_constraint\": None,\n",
    "            \"b_constraint\": None,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1763656596949,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "iIZppsfEcaVN",
    "outputId": "d04a3982-bfcb-4e73-d05a-b41f663446e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4748, 1)\n",
      "                                                   0\n",
      "0                              >1pos|ACP20mainTest|1\n",
      "1  CETWRTETTGATGQASSLLSGRLLEQKAASCHNSYIVLCIENSFMT...\n",
      "2                              >2pos|ACP20mainTest|1\n",
      "3  DERCTIIIHPGSPCDPSDCVQYCYAEYNGVGKCIASKPGRSANCMC...\n",
      "4                              >3pos|ACP20mainTest|1\n",
      "(2690, 1)\n",
      "                       0\n",
      "0  >1pos|ACP20mainTest|1\n",
      "1            FLWWLFKWAWK\n",
      "2  >2pos|ACP20mainTest|1\n",
      "3          FAKLAKKALAKLL\n",
      "4  >3pos|ACP20mainTest|1\n"
     ]
    }
   ],
   "source": [
    "inFastaTrain=\"/content/Train_set.fasta\"\n",
    "inFastaTest=\"/content/Independent_test_converted.fasta\"\n",
    "\n",
    "mainTrain = fasta2csv(inFastaTrain)\n",
    "mainTest = fasta2csv(inFastaTest)\n",
    "\n",
    "# Train set\n",
    "mainTrain[\"Tags\"] = mainTrain[\"PID\"].apply(lambda pid: 1 if str(pid)[-1] == \"1\" else 0)\n",
    "\n",
    "# Test set\n",
    "mainTest[\"Tags\"] = mainTest[\"PID\"].apply(lambda pid: 1 if str(pid)[-1] == \"1\" else 0)\n",
    "\n",
    "# Convert to numpy array\n",
    "ACP_y_train = mainTrain[\"Tags\"].values\n",
    "ACP_y_test = mainTest[\"Tags\"].values\n",
    "\n",
    "ACP_y_train_ = np.array(ACP_y_train, dtype=int)\n",
    "ACP_y_test_ = np.array(ACP_y_test, dtype=int)\n",
    "\n",
    "x_train = {}\n",
    "protein_index = 1\n",
    "for line in mainTrain[\"Seq\"]:\n",
    "  x_train[protein_index] = line\n",
    "  protein_index = protein_index + 1\n",
    "maxlen_train = max(len(x) for x in x_train.values())\n",
    "\n",
    "x_test = {}\n",
    "protein_index = 1\n",
    "for line in mainTest[\"Seq\"]:\n",
    "  x_test[protein_index] = line\n",
    "  protein_index = protein_index + 1\n",
    "maxlen_test = max(len(x) for x in x_test.values())\n",
    "\n",
    "maxlen = max(maxlen_train,maxlen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1763656597178,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "r7Q_2t0jcdpr"
   },
   "outputs": [],
   "source": [
    "#Convert amino acids to vectors\n",
    "def OE(seq_temp):\n",
    "    seq = seq_temp\n",
    "    chars = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
    "    fea = []\n",
    "    tem_vec =[]\n",
    "    #k = 6\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] =='A':\n",
    "            tem_vec = [1]\n",
    "        elif seq[i]=='C':\n",
    "            tem_vec = [2]\n",
    "        elif seq[i]=='D':\n",
    "            tem_vec = [3]\n",
    "        elif seq[i]=='E' or seq[i]=='U':\n",
    "            tem_vec = [4]\n",
    "        elif seq[i]=='F':\n",
    "            tem_vec = [5]\n",
    "        elif seq[i]=='G':\n",
    "            tem_vec = [6]\n",
    "        elif seq[i]=='H':\n",
    "            tem_vec = [7]\n",
    "        elif seq[i]=='I':\n",
    "            tem_vec = [8]\n",
    "        elif seq[i]=='K':\n",
    "            tem_vec = [9]\n",
    "        elif seq[i]=='L':\n",
    "            tem_vec = [10]\n",
    "        elif seq[i]=='M' or seq[i]=='O':\n",
    "            tem_vec = [11]\n",
    "        elif seq[i]=='N':\n",
    "            tem_vec = [12]\n",
    "        elif seq[i]=='P':\n",
    "            tem_vec = [13]\n",
    "        elif seq[i]=='Q':\n",
    "            tem_vec = [14]\n",
    "        elif seq[i]=='R':\n",
    "            tem_vec = [15]\n",
    "        elif seq[i]=='S':\n",
    "            tem_vec = [16]\n",
    "        elif seq[i]=='T':\n",
    "            tem_vec = [17]\n",
    "        elif seq[i]=='V':\n",
    "            tem_vec = [18]\n",
    "        elif seq[i]=='W':\n",
    "            tem_vec = [19]\n",
    "        elif seq[i]=='X' or seq[i]=='B' or seq[i]=='Z':\n",
    "            tem_vec = [20]\n",
    "        elif seq[i]=='Y':\n",
    "            tem_vec = [21]\n",
    "        #fea = fea + tem_vec +[i]\n",
    "        fea.append(tem_vec)\n",
    "    return fea\n",
    "\n",
    "x_train_oe = []\n",
    "for i in x_train:\n",
    "  oe_feature = OE(x_train[i])\n",
    "  x_train_oe.append(oe_feature)\n",
    "  #print(protein_seq_dict[i])\n",
    "\n",
    "x_test_oe = []\n",
    "for i in x_test:\n",
    "  oe_feature = OE(x_test[i])\n",
    "  x_test_oe.append(oe_feature)\n",
    "\n",
    "x_train_ = np.array(pad_sequences(x_train_oe, padding='post', maxlen=maxlen))\n",
    "x_test_ = np.array(pad_sequences(x_test_oe, padding='post', maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1763656597428,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "z7c4P4mnciZm"
   },
   "outputs": [],
   "source": [
    "handcraft_AAC_train = [[0] * 21 for _ in range(len(x_train_oe))]\n",
    "for row in range(len(x_train_oe)):\n",
    "  seq = x_train_oe[row]\n",
    "  for i in seq:\n",
    "    col = i[0]-1\n",
    "    handcraft_AAC_train[row][col] += 1/len(seq)\n",
    "hc_AAC_train = np.array(handcraft_AAC_train)\n",
    "\n",
    "handcraft_AAC_test = [[0] * 21 for _ in range(len(x_test_oe))]\n",
    "for row in range(len(x_test_oe)):\n",
    "  seq = x_test_oe[row]\n",
    "  for i in seq:\n",
    "    col = i[0]-1\n",
    "    handcraft_AAC_test[row][col] += 1/len(seq)\n",
    "hc_AAC_test = np.array(handcraft_AAC_test)\n",
    "\n",
    "comb = []\n",
    "for i in range(1,22):\n",
    "  for j in range(i,22):\n",
    "    comb.append([i,j])\n",
    "comb_index = {}\n",
    "for i in range(len(comb)):\n",
    "  comb_index[tuple(comb[i])] = i\n",
    "\n",
    "handcraft_DPC_train = [[0] * len(comb) for _ in range(len(x_train_oe))]\n",
    "for row in range(len(x_train_oe)):\n",
    "  seq = x_train_oe[row]\n",
    "  for i in range(len(seq)-1):\n",
    "    a = sorted([seq[i][0],seq[i+1][0]])\n",
    "    index = comb_index[tuple(a)]\n",
    "    handcraft_DPC_train[row][index] += 1/(len(seq)-1)\n",
    "hc_DPC_train = np.array(handcraft_DPC_train)\n",
    "\n",
    "handcraft_DPC_test = [[0] * len(comb) for _ in range(len(x_test_oe))]\n",
    "for row in range(len(x_test_oe)):\n",
    "  seq = x_test_oe[row]\n",
    "  for i in range(len(seq)-1):\n",
    "    a = sorted([seq[i][0],seq[i+1][0]])\n",
    "    index = comb_index[tuple(a)]\n",
    "    handcraft_DPC_test[row][index] += 1/(len(seq)-1)\n",
    "hc_DPC_test = np.array(handcraft_DPC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2455,
     "status": "ok",
     "timestamp": 1763656599886,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "6OA4qnfCclbi"
   },
   "outputs": [],
   "source": [
    "def readFasta(file):\n",
    "    if os.path.exists(file) == False:\n",
    "        print('Error: \"' + file + '\" does not exist.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(file) as f:\n",
    "        records = f.read()\n",
    "\n",
    "    if re.search('>', records) == None:\n",
    "        print('The input file seems not in fasta format.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    records = records.split('>')[1:]\n",
    "    myFasta = []\n",
    "    for fasta in records:\n",
    "        array = fasta.split('\\n')\n",
    "        name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n",
    "        myFasta.append([name, sequence])\n",
    "\n",
    "    return myFasta\n",
    "def generateGroupPairs(groupKey):\n",
    "    gPair = {}\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPair[key1+'.'+key2] = 0\n",
    "    return gPair\n",
    "\n",
    "\n",
    "def CKSAAGP(fastas, gap = 5, **kw):\n",
    "\n",
    "    group = {\n",
    "        'alphaticr': 'GAVLMI',\n",
    "        'aromatic': 'FYW',\n",
    "        'postivecharger': 'KRH',\n",
    "        'negativecharger': 'DE',\n",
    "        'uncharger': 'STCPNQ'\n",
    "    }\n",
    "\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "\n",
    "    groupKey = group.keys()\n",
    "\n",
    "    index = {}\n",
    "    for key in groupKey:\n",
    "        for aa in group[key]:\n",
    "            index[aa] = key\n",
    "\n",
    "    gPairIndex = []\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPairIndex.append(key1+'.'+key2)\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for g in range(gap + 1):\n",
    "        for p in gPairIndex:\n",
    "            header.append(p+'.gap'+str(g))\n",
    "    encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        for g in range(gap + 1):\n",
    "            gPair = generateGroupPairs(groupKey)\n",
    "            sum = 0\n",
    "            for p1 in range(len(sequence)):\n",
    "                p2 = p1 + g + 1\n",
    "                if p2 < len(sequence) and sequence[p1] in AA and sequence[p2] in AA:\n",
    "                    gPair[index[sequence[p1]]+'.'+index[sequence[p2]]] = gPair[index[sequence[p1]]+'.'+index[sequence[p2]]] + 1\n",
    "                    sum = sum + 1\n",
    "\n",
    "            if sum == 0:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(0)\n",
    "            else:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(gPair[gp] / sum)\n",
    "\n",
    "        encodings.append(code)\n",
    "\n",
    "    return encodings\n",
    "\n",
    "handcraft_CKSAAGP_train = CKSAAGP(readFasta(inFastaTrain))\n",
    "handcraft_CKS_train = []\n",
    "for i in range(1,len(handcraft_CKSAAGP_train)):\n",
    "  handcraft_CKS_train.append(handcraft_CKSAAGP_train[i][1:])\n",
    "hc_CKS_train = np.array(handcraft_CKS_train)\n",
    "\n",
    "handcraft_CKSAAGP_test = CKSAAGP(readFasta(inFastaTest))\n",
    "handcraft_CKS_test = []\n",
    "for i in range(1,len(handcraft_CKSAAGP_test)):\n",
    "  handcraft_CKS_test.append(handcraft_CKSAAGP_test[i][1:])\n",
    "hc_CKS_test = np.array(handcraft_CKS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45775,
     "status": "ok",
     "timestamp": 1763656645665,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "6QMhGJJ2cqd6",
    "outputId": "f8fa872c-bf38-492f-fa13-cde74f19f221"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3572521970.py:91: DeprecationWarning: The numpy.linalg.linalg has been made private and renamed to numpy.linalg._linalg. All public functions exported by it are available from numpy.linalg. Please use numpy.linalg.svd instead.\n",
      "  protein_tri_fea = get_4_nucleotide_composition(protein_tris, protein_seq, pythoncount =False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1345, 745)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TransDict_from_list(groups):\n",
    "  transDict = dict()\n",
    "  tar_list = ['0', '1', '2', '3', '4', '5', '6']\n",
    "  result = {}\n",
    "  index = 0\n",
    "  for group in groups:\n",
    "    g_members = sorted(group)  # Alphabetically sorted list\n",
    "    for c in g_members:\n",
    "        # print('c' + str(c))\n",
    "        # print('g_members[0]' + str(g_members[0]))\n",
    "        result[c] = str(tar_list[index])  # K:V map, use group's first letter as represent.\n",
    "    index = index + 1\n",
    "  return result\n",
    "def translate_sequence(seq, TranslationDict):\n",
    "  '''\n",
    "  Given (seq) - a string/sequence to translate,\n",
    "  Translates into a reduced alphabet, using a translation dict provided\n",
    "  by the TransDict_from_list() method.\n",
    "  Returns the string/sequence in the new, reduced alphabet.\n",
    "  Remember - in Python string are immutable..\n",
    "  '''\n",
    "  import string\n",
    "  from_list = []\n",
    "  to_list = []\n",
    "  for k, v in TranslationDict.items():\n",
    "      from_list.append(k)\n",
    "      to_list.append(v)\n",
    "  # TRANS_seq = seq.translate(str.maketrans(zip(from_list,to_list)))\n",
    "  TRANS_seq = seq.translate(str.maketrans(str(from_list), str(to_list)))\n",
    "  # TRANS_seq = maketrans( TranslationDict, seq)\n",
    "  return TRANS_seq\n",
    "def get_3_protein_trids():\n",
    "  nucle_com = []\n",
    "  chars = ['0', '1', '2', '3', '4', '5', '6']\n",
    "  base = len(chars)\n",
    "  end = len(chars) ** 3\n",
    "  for i in range(0, end):\n",
    "      n = i\n",
    "      ch0 = chars[n % base]\n",
    "      n = n / base\n",
    "      ch1 = chars[int(n % base)]\n",
    "      n = n / base\n",
    "      ch2 = chars[int(n % base)]\n",
    "      nucle_com.append(ch0 + ch1 + ch2)\n",
    "  return nucle_com\n",
    "def get_4_nucleotide_composition(tris, seq, pythoncount=True):\n",
    "  seq_len = len(seq)\n",
    "  tri_feature = [0] * len(tris)\n",
    "  k = len(tris[0])\n",
    "  note_feature = [[0 for cols in range(len(seq) - k + 1)] for rows in range(len(tris))]\n",
    "  if pythoncount:\n",
    "      for val in tris:\n",
    "          num = seq.count(val)\n",
    "          tri_feature.append(float(num) / seq_len)\n",
    "  else:\n",
    "      # tmp_fea = [0] * len(tris)\n",
    "      for x in range(len(seq) + 1 - k):\n",
    "          kmer = seq[x:x + k]\n",
    "          if kmer in tris:\n",
    "              ind = tris.index(kmer)\n",
    "              # tmp_fea[ind] = tmp_fea[ind] + 1\n",
    "              note_feature[ind][x] = note_feature[ind][x] + 1\n",
    "      # tri_feature = [float(val)/seq_len for val in tmp_fea]    #tri_feature type:list len:256\n",
    "      u, s, v = la.svd(note_feature)\n",
    "      for i in range(len(s)):\n",
    "          tri_feature = tri_feature + u[i] * s[i] / seq_len\n",
    "      # print tri_feature\n",
    "      # pdb.set_trace()\n",
    "\n",
    "  return tri_feature\n",
    "def prepare_feature_kmer(infile):\n",
    "  protein_seq_dict = {}\n",
    "  protein_index = 1\n",
    "  with open(infile, 'r') as fp:\n",
    "    for line in fp:\n",
    "      if line[0] != '>':\n",
    "        seq = line[:-1]\n",
    "        protein_seq_dict[protein_index] = seq\n",
    "        protein_index = protein_index + 1\n",
    "  kmer = []\n",
    "  groups = ['AGV', 'ILFP', 'YMTS', 'HNQW', 'RK', 'DE', 'C']\n",
    "  group_dict = TransDict_from_list(groups)\n",
    "  protein_tris = get_3_protein_trids()\n",
    "  # get protein feature\n",
    "  # pdb.set_trace()\n",
    "  for i in protein_seq_dict:  # and protein_fea_dict.has_key(protein) and RNA_fea_dict.has_key(RNA):\n",
    "    protein_seq = translate_sequence(protein_seq_dict[i], group_dict)\n",
    "    # print('oe:',shape(oe_feature))\n",
    "    # pdb.set_trace()\n",
    "    # RNA_tri_fea = get_4_nucleotide_composition(tris, RNA_seq, pythoncount=False)\n",
    "    protein_tri_fea = get_4_nucleotide_composition(protein_tris, protein_seq, pythoncount =False)\n",
    "    kmer.append(protein_tri_fea)\n",
    "    protein_index = protein_index + 1\n",
    "    # chem_fea.append(chem_tmp_fea)\n",
    "  return np.array(kmer)\n",
    "\n",
    "kmer_train = prepare_feature_kmer(inFastaTrain)\n",
    "kmer_test = prepare_feature_kmer(inFastaTest)\n",
    "\n",
    "hc_train = np.c_[hc_AAC_train,hc_DPC_train,hc_CKS_train,kmer_train]\n",
    "hc_train.shape\n",
    "\n",
    "hc_test = np.c_[hc_AAC_test,hc_DPC_test,hc_CKS_test,kmer_test]\n",
    "hc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8349,
     "status": "ok",
     "timestamp": 1763657268406,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "lO63gXPh3igF",
    "outputId": "f6e86826-f26d-4feb-b912-2d4ec8a3f0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#model esemble\n",
    "import joblib\n",
    "model1 = keras.models.load_model(\"bilstm_attention_main8253.keras\",custom_objects={\"Attention\": Attention})\n",
    "model2 = joblib.load(filename='lgbm_main8378_hc.joblib')\n",
    "model3 = joblib.load(filename='xgboost_main8105.joblib')\n",
    "model4 = joblib.load(filename='svm_rbf_hc.joblib')\n",
    "model5 = keras.models.load_model(\"best_RF_k331.keras\") # Corrected filename\n",
    "model6 = joblib.load(filename='random_forest_aac.joblib')\n",
    "\n",
    "result1 = model1.predict([x_test_,hc_test]).tolist()\n",
    "result1_new = []\n",
    "for i in result1:\n",
    "  if i[0] < 0.5:\n",
    "    result1_new.append(0)\n",
    "  else:\n",
    "    result1_new.append(1)\n",
    "result1_new = np.array(result1_new)\n",
    "\n",
    "x_test_1 = np.squeeze(x_test_)\n",
    "X_test = np.c_[hc_test,x_test_1]\n",
    "\n",
    "# Predict for model 2 (LightGBM) - Added prediction for result2\n",
    "result2 = model2.predict_proba(hc_test)[:, 1]\n",
    "\n",
    "# Predict for model 3 (xgboost)\n",
    "result3 = model3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predict for model 4 (svm) - Changed to predict() as predict_proba requires probability=True during training\n",
    "result4 = model4.predict(hc_test)\n",
    "\n",
    "# Predict for model 6 (random_forest_aac) - Corrected input to X_test\n",
    "result6 = model6.predict_proba(hc_AAC_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1820,
     "status": "ok",
     "timestamp": 1763657590337,
     "user": {
      "displayName": "Thắng Nguyễn",
      "userId": "00154661689050136414"
     },
     "user_tz": -420
    },
    "id": "Y-RdhdWFzkir",
    "outputId": "e652d9e2-3f0c-4972-956f-eb747cbfe5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test_oe: (1345, 50, 1)\n",
      "Shape of SF_test: (1345, 331)\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "accuracy_score: 0.9063197026022305\n",
      "precision_score: 0.9147602155421081\n",
      "recall_score: 0.9063197026022305\n",
      "f1_score: 0.9090878417835683\n",
      "[[989  87]\n",
      " [ 39 230]]\n"
     ]
    }
   ],
   "source": [
    "x_test_oe = np.load(\"x_test_oe (2).npy\")\n",
    "SF_test = np.load(\"SF_ALL_K_test_RF_k331.npy\")\n",
    "print(\"Shape of x_test_oe:\", x_test_oe.shape)\n",
    "print(\"Shape of SF_test:\", SF_test.shape)\n",
    "result5 = model5.predict([x_test_oe,SF_test]).tolist()\n",
    "result5_new = []\n",
    "for i in result5:\n",
    "  if i[0] < 0.5:\n",
    "    result5_new.append(0)\n",
    "  else:\n",
    "    result5_new.append(1)\n",
    "result5_new = np.array(result5_new)\n",
    "\n",
    "final_result = []\n",
    "for i in range(len(result1_new)):\n",
    "  score = result1_new[i]*0.3 + result6[i]*0.5 + result5_new[i]*0.2\n",
    "  if score >= 0.5:\n",
    "    final_result.append(1)\n",
    "  else:\n",
    "    final_result.append(0)\n",
    "final_result = np.array(final_result)\n",
    "\n",
    "final_result\n",
    "\n",
    "from sklearn.metrics import *\n",
    "print(\"accuracy_score:\",str(accuracy_score(ACP_y_test_,final_result)))\n",
    "print(\"precision_score:\",str(precision_score(ACP_y_test_,final_result,average = 'weighted')))\n",
    "print(\"recall_score:\" , str(recall_score(ACP_y_test_,final_result,average = 'weighted')))\n",
    "print(\"f1_score:\",str(f1_score(ACP_y_test_,final_result,average = 'weighted')))\n",
    "\n",
    "print(confusion_matrix(ACP_y_test_,final_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx97ffWPMAVD"
   },
   "source": [
    "Kết quả các mô hình trong kênh Model Mix\n",
    "1. SVM\n",
    "\n",
    "\n",
    "*   Accuracy: 0.8892\n",
    "*   Precision: 0.9037\n",
    "*   Recall: 0.8892\n",
    "*   F1-score: 0.8937\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "[[967 109]\n",
    "\n",
    " [ 40 229]]\n",
    "\n",
    "2. XGBoost\n",
    "*   Accuracy: 0.9115\n",
    "*   Precision: 0.9171\n",
    "*   Recall: 0.9115\n",
    "*   F1-score: 0.9135\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "[[999  77]\n",
    "\n",
    " [ 42 227]]\n",
    "\n",
    "3. LightGBM\n",
    "*   Accuracy: 0.9100\n",
    "*   Precision: 0.9185\n",
    "*   Recall: 0.9100\n",
    "*   F1-score: 0.9127\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "[[991  85]\n",
    "\n",
    " [ 36 233]]\n",
    "\n",
    "4. Random Forest\n",
    "*   Accuracy: 0.9063\n",
    "*   Precision: 0.9148\n",
    "*   Recall: 0.9063\n",
    "*   F1-score: 0.9091\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "[[989  87]\n",
    "\n",
    " [ 39 230]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CUNXCxLKPG1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
